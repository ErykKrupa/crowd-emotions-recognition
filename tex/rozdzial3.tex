\chapter{Analiza problemu}
\thispagestyle{chapterBeginStyle}
\label{chapter3}


W tym rozdziale został przedstawiony problem analizy emocji na zdjęciach tłumów i grup ludzi, dotychczasowe podejścia do tego problemu, jak również podejście zastosowane w tej pracy.


\section{Szczegółowe przedstawienie problemu}
Celem pracy jest wytrenowania skutecznego modelu konwolucyjnej sieci neuronowej umożliwiającego klasyfikacje emocji dominującej wśród dużej grupy osób na podstawie obrazu, ze szczególnym naciskiem na to, by wytrenowany model był jak najlżejszy, a czas rozpoznawania emocji- jak najkrótszy. Tak skonstruowana, niewielka sieć może zostać bez problemów zapisana na urządzeniu mobilnym. Z kolei wysoka szybkość działania umożliwia analizę obrazu w czasie zbliżonym do czasu rzeczywistego. Obie te cechy pozwolą na stworzenie aplikacji mobilnej, która np. będzie robić zdjęcia za każdym razem, kiedy w kadrze zostaną rozpoznane emocje pozytywne.

Rozpoznawane emocje będą przypisywane do jednej z trzech grup: emocji pozytywnych, neutralnych i negatywnych. Domyślnym podejściem do podobnych problemów jest dzielenie ich na przynajmniej dwie części. Na początku trenowany się model będący w stanie wykrywać twarze na zdjęciach tłumów. Fragmenty obrazu zawierające twarze są następnie przekazywane do drugiego modelu odpowiedzialnego za rozpoznawanie emocji, który uśrednia je za pomocą konkretnego algorytmu. Takie podejście ma jednak oczywistą wadę, a mianowicie wykrywa się jedynie emocje wyrażone na twarzach, a pomija się te, które wynikają chociażby z mowy ciała. Z tego powodu często trenuje się jeszcze jeden model, mający na celu zbadać ogólne cechy danej sceny, tj. ocenić ogólny nastrój zdjęcia. Dopiero tą wartość łączy się z uśrednionymi emocjami twarzy i zwraca jako przewidywaną, ogólną emocje panującą na zdjęciu.
 
 
\section{Analiza i porównanie istniejących rozwiązań}
W kontekście rozpoznawania emocji na zdjęciach tłumów, a w szczególności w przypadku podziału tych emocji na trzy wyżej wymienione kategorie, wartą przytoczenia jest praca \cite{GAD}. Autorzy stworzyli zbiór Group Effect Database 3.0 (zobacz rozdział \ref{chapter4}), na którym przetestowali modele będące w istocie połączeniem modeli $BoW_{AU}$, $BoW_{LL}$, $Scene_{GIST}$ \cite{GIST} i $Scene_{CENTRIST}$ \cite{CENTRIST}.

$BoW$ (Bag of Word) \cite{BoW} to reprezentacja, która opiera się na przypisywaniu słów do analizowanych danych, tworząc tym samym zbiór niepowiązanych ze sobą słów kluczowych.
$BoW_{AU}$ analizuje napięcie mięśni twarzy, wykorzystując $BoW$ do przypisywania słów kluczowych do każdej twarzy na zdjęciu, tworząc w ten sposób zbiór słów związanych z mimiką, takich jak np. uśmiech, szczęście, itd.
$BoW_{LL}$ wykrywa niskopoziomowe cechy zdjęć twarzy, takie jak np. krawędzie, nasycenie kolorów czy oświetlenie. 
$Scene_{GIST}$ i $Scene_{CENTRIST}$ to w istocie deskryptory sceny- analizują cechy zdjęć nie związane z twarzami, ale z elementy otoczenia, takie jak wystrój scenerii, ale też np. ogólny sposób ubioru postaci na zdjęciu.
Należy jeszcze dodać, że autorzy w łączeniu modeli wykorzystywali Multiple Kernel Learning ($MKL$) \cite{MKL}. 

Żaden z tych modeli nie zapewnia na walidacyjnym zbiorze danych dokładności wyższej niż 51\%. Jednakże ich połączenie pozwoliło na osiągnięcie zdecydowanie lepszych wyników. \cite{GAD} osiągnął najlepsze rezultaty (na poziomie 67.64\% na zbiorze walidacyjnym), łącząc $BoW_{AU}$, $BoW_{LL}$ i $Scene_{CENTRIST}$ za pomocą $MKL$. Na ten wynik złożyło się 83.72\% dokładności dla zdjęć emocji pozytywnych, 80\% dla emocji neutralnych i tylko 31.03\% dla emocji negatywnych. Biorąc pod uwagę, że zbiór zdjęć przedstawiających emocje negatywne w bazie Group Effect Database 3.0 jest najmniejszy, można pokusić się o wniosek, że taka architektura wręcz dopasowała się do zbioru, na którym była trenowa. 31.03\% ta wartość nawet niższa, niż przewidywana w przypadku zwracania wyników losowych dla klasyfikacji trójklasowej. Można więc wysnuć tezę, że podana architektura była w stanie poprawnie rozpoznawać tylko emocje pozytywne i neutralne.

Inna zaprezentowana przez \cite{GAD} architektura, składająca się z $BoW_{AU}$, $BoW_{LL}$ i $Scene_{GIST}$ połączonych za pomocą $MKL$, uzyskała, co prawda, nieznacznie gorszą ostateczną dokładność (67.15\%), jednakże osiągając wynik na poziomie 50\% dla zdjęć emocji negatywnych.

Kolejnym przykładem pracy poruszającej temat trójklasowej klasyfikacji w problemie rozpoznawania emocji tłumów jest \cite{SGarg}. Autor wykorzystuje hybrydowy system, który składa się z głębokich konwolucyjnych sieci neuronowych i klasyfikatora bayesowskiego. Na początku wydobywa zdjęcia twarzy z obrazu przedstawiającego tłum lub grupę ludzi, a następnie przekazuje je do sieci neuronowych, które analizują wyrażane emocje na poszczególnych zdjęciach twarzy zwracając uśredniony wynik. Jednocześnie, klasyfikator bayesowski wykorzystuje deskryptor sceny, by wydobyć ze zdjęcia wizualne cechy otoczenia, a następnie integruje je, przewidując globalną emocję związaną z obrazem. Na końcu sieci neuronowe przekazują rozpoznane emocje do klasyfikatora, a ten zwraca ostateczną, ogólną decyzje odnośnie emocji panującej na zdjęciu. Wykorzystując bazę zdjęć Group Affect Datebase 3.0 do trenowania powyższych modeli, \cite{SGarg} osiągnął wynik na poziomie 65.27\% dokładności na walidacyjnym zbiorze danych.


\section{Zastosowane podejścia do rozwiązania problemu}
Jednakże w tej pracy przetestowane zostaną nieco inne podejścia do tego problemu. Pierwszym z nich jest zaimplementowanie jednego model sieci neuronowej, który analizuje całe zdjęcie i określa dominującą na nim emocje. To podejście zostanie wsparte techniką augmentacji danych. Największą jego zaletą jest niewielka waga wytrenowanego modelu i krótki czas przetwarzania zdjęć. Umożliwi to wykorzystanie sieci w aplikacjach przeznaczonych na urządzenia mobilne, których celem jest analiza emocji panujących na zdjęciach w czasie zbliżonym do rzeczywistego. Kolejną zaletą tego podejścia jest konieczność zaimplementowania tylko jednego modelu, z jednoczesnym uwzględnienia zarówno emocji wypisanych na twarzach, tych wynikających z mowy ciała, jak i tych, na które wskazuje ubiór postaci czy otoczenie.

Drugim zastosowanym podejściem jest wykorzystanie modeli wytrenowanych wcześniej (transfer learning) na innych, dużo większych i bardziej ogólnych zbiorach danych, w celu skorzystania z ich przestrzennej hierarchii cech w charakterze ogólnego modelu przetwarzania obrazu. Taką hierarchię można wykorzystać do rozpoznawania klas, do których sieć nie była wcześniej szkolona. Może to szczególnie zwiększyć wydajność modelu w przypadku problemów związanych ze zbytnim dopasowywaniem się sieci do zbioru treningowego.
