\chapter{Wprowadzenie do uczenia maszynowego}
\thispagestyle{chapterBeginStyle}
\label{chapter2}


\section{Podstawowe pojęcia}
Poniżej znajdują się najważniejsze pojęcia, których znajomość jest niezbędna podczas lektury niniejszej pracy.

Sztuczna inteligencja (ang. artificial intelligence)- zautomatyzowany proces myślowy standardowo wykonywany przez ludzi, zdolny do podejmowania decyzji na podstawie analizy środowiska, dążący do maksymalizacji szansy na pomyślne osiągnięcie zdefiniowanego celu.

Uczenie maszynowe (ang. machine learning)- forma sztucznej inteligencji zdolna do doskonalenia się poprzez doświadczenie. Podczas, gdy klasyczne algorytmy wykorzystują zdefiniowane przez programistę reguły do przetwarzania danych w celu uzyskania pewnych wyników, algorytmy uczenia maszynowego wykorzystują dane i uprzednio uzyskane wyniki, w celu tworzenia i doskonalenia reguł przetwarzania nowych, podobnych danych.

Uczenie głębokie (ang. machine learning)- dziedzina uczenia maszynowego, sposób uczenia się, który kładzie nacisk na trenowanie modeli o wielu warstwach, z których każda kolejna stanowi coraz to lepszą reprezencję rozpatrywanych danych. Z reguły tymi modelami są sztuczne sieci neuronowe.

Sztuczna sieć neuronowa (ang. artificial neural network)- struktura realizująca obliczenia za pomocą kolejnych warstw elementów przetwarzających, tj. sztucznych neuronów (ang. artificial neuron) zdolnych do odbierania sygnału, przetwarzania go i przekazywania do kolejnych neuronów. Sygnał jest reprezentowany przez liczbę rzeczywistą, a obliczany jest za pomocą nieliniowej fukcji zwanej funkcją aktywacji (ang. activation function). Z reguły neurony są zaagregowane w warstwy (ang. layers), a każda z warst ma przypisaną fukcję aktywacji. W najprostrzych modelach sekwencyjnych sygnały są przekazywane od warstwy wejściowej (ang. input layer), kolejno przez wszystkie warstwy, aż do warstwy wyjściowej (ang. output layer). Warstwę nazywamy gęsto połączoną, jeśli każdy jej neuron jest połączony z każdym z wartwy kolejnej. Ponadto, z każdym neuronem związany jest bias (ang. bias), czyli wartość, która musi być przekroczona, aby neuron przekazywał sygnał. Połączenia między neuronami reprezentowane są przez zmienne zwane wagami (ang. weights). Modyfikowanie wag i biasów w trakcie prowadzenia obliczeń pozwala na dostrajanie modelu, czyli uczenie się sztucznej sieci neuronowej. Do tego celu potrzebne są dane treningowe, wraz z przypisanymi im etykietami docelowymi. Podczas nauki, sieć wykorzystuje funkcje straty (ang. loss function) do porównywania wartości etykiet docelowych z tymi przewidywanymi przez model. Na podstawie wyniku tej funkcji sieć jest w stanie określić, jak odległa była jej odpowiedź od odpowiedzi idealnej. Ta wiedza wykorzystywana jest przez optymalizator (ang. optimizer) w celu dostrajania sieci.

Konwolucyjna sieć neuronowa (ang. convolutional neural network, CNN, ConvNet)- to szczególna klasa sieci neuronowych, szeroko wykorzystywana w analizie obrazów i wideo z uwagi na przewagę nad klasycznymi sieciami neuronowymi w przynajmniej dwóch aspektach. Podstawową różnicą między siecią gęsto połączoną, a siecią konwolucyjną jest to, że ta pierwsza uczy się rozpoznawania cech globalnych, a ta druga- lokalnych wzorców. W przypadku obrazów cechy są znajdowane w małych, dwuwymiarowych oknach danych wejściowych (czyli małych wycinkach obrazu w przypadku analizy podejmowanej przez pierwszą warstwę sieci). Dzięki temu, wzorce obrazu rozpoznawane przez model są niezależne od pozycji tego wzorca na obrazie. Dla przykładu, sieć konwolucyjna po rozpoznaniu określonego wzoru w prawym dolnym rogu obrazu może rozpoznać go również np. w lewym górnym rogu obrazu. Sieć gęsta musiała by nauczyć się tej cechy na nowo. Oznacza to, że modele konwolucyjne nie wiążą kształtu z jego położeniem w kadrze. Z tego powodu charakteryzują się one większą wydajnością. Drugą zaletą sieci konwolucyjnych jest to, że uczą się na przestrzeni hierarchii wzorów. Oznacza to, że pierwsze warstwy uczą się małych lokalnych wzorców, takich jak na przykład krawędzie czy tekstury, a kolejne bardziej skomplikowanych struktur składających się z elementów rozpoznanych przez wartwy poprzednie, itd. Takie podejście pozwala na wydajne uczenie się coraz bardziej złożonych i abstrakcyjnych koncepcji graficznych.


\section{Przegląd literatury związanej z uczeniem głębokim}

Poniżej znajduje się kilka wybranych pozycji ogólnie związanych z implementacją sieci neuronowych.

W 1989 roku \cite{BackpropagationLeCun} zaimplementował algorytm propagacji wstecznej w modelu głębokim, w celu rozpoznawania ręcznie pisanych cyfr w wiadomościach pocztowych. Baza danych składała się z 9298 cyfr różnej wielkości, napisanych przez wielu ludzi o różnych stylach pisania. Algorytm propagacji wstecznej pozwolił trenować sieć zaskakująco szybko, biorąc pod uwagę wielkość zbioru danych. Model znalazł zastosowanie w komercyjnych maszynach automatyzujących proces odczytywania ręcznie pisanych cyfr.

W 1992 roku \cite{Cresceptron} zaimplementował model o nazwie Cresceptron, który wykorzystywał uczenie nienadzorowane (nie wymagał wcześniejszego etykietowania danych przez programistów) do rozpoznawania obiektów w kadrach, w których było ich bardzo wiele. Cresceptron uczył się dowolnej liczby cech dla każdej warstwy, a każda cecha była reprezentowana przez jądro konwolucji. Był to pierwszy model wykorzystujący wartwy max pooling do redukcji rozdzielczości tensorów przyjmowanych przez daną warstwę- analizowały one okna konwolucji o rozmiarze 2x2 z krokiem równym 2 (patrz rozdział \ref{chapter4}). 

W problemach rozpoznawania mowy często używana jest rekurencyjna sieć neuronowa opublikowana w 1997 przez \cite{LSTMSchmidhuber}, wykorzystująca metodę zwaną long short-term memory (LSTM). Ta sieć jest zdolna do rozwiązywania problemów, które wymagają pamięci o wydarzeniach, które miały miejsce tysiące kroków temu, co jest istotne w kontekście rozpoznawania mowy. 6 lat później LSTM zaczęło konkurować w rozwiązywaniu pewnych problemów z tradycyjnymi sieciami rozpoznającymi mowę \cite{LSTMGraves}. Później sieci LSTM zostały połączone z CTC (connectionist temporal classification) \cite{CTC}, co zostało wykorzystane przez firmę Google w 2015 roku do podniesienia wydajności sieci rozpoznających mowę w oparciu o dane zebrane dzięki Google Voice Search \cite{GVS}.

Rok 2009 przyniósł przełom w dziedzinie sprzętu wykorzystywanego do trenowania sztucznych sieci neuronowych. Firma Nvidia wytrenowała model na procesorze graficznym, udowadniając, że GPU może zwiększyć szybkość trenowania sieci około 100-krotnie, w szczególności świetnie radząc sobie z obliczeniami przeprowadzanymi na tensorach \cite{GPUOh}. 
