\chapter{Wprowadzenie do uczenia maszynowego}
\thispagestyle{chapterBeginStyle}
\label{chapter2}


\section{Podstawowe pojęcia}
Poniżej znajdują się najważniejsze pojęcia, których znajomość jest niezbędna podczas lektury niniejszej pracy.

Sztuczna inteligencja (ang. artificial intelligence) - zautomatyzowany proces myślowy standardowo wykonywany przez ludzi, zdolny do podejmowania decyzji na podstawie analizy środowiska, dążący do maksymalizacji szansy na pomyślne osiągnięcie zdefiniowanego celu.

Uczenie maszynowe (ang. machine learning) - forma sztucznej inteligencji zdolna do doskonalenia się poprzez doświadczenie. Podczas gdy klasyczne algorytmy wykorzystują zdefiniowane przez programistę reguły do przetwarzania danych w celu uzyskania pewnych wyników, algorytmy uczenia maszynowego wykorzystują dane i uprzednio uzyskane wyniki, w celu tworzenia i doskonalenia reguł przetwarzania nowych, podobnych danych.

Uczenie głębokie (ang. machine learning) - dziedzina uczenia maszynowego, sposób uczenia się, który kładzie nacisk na trenowanie modeli o wielu warstwach, z których każda kolejna stanowi coraz to lepszą reprezentację rozpatrywanych danych. Z reguły tymi modelami są sztuczne sieci neuronowe.

Sztuczna sieć neuronowa (ang. artificial neural network) - struktura realizująca obliczenia za pomocą kolejnych warstw elementów przetwarzających, tj. sztucznych neuronów (ang. artificial neuron) zdolnych do odbierania sygnału, przetwarzania go i przekazywania do kolejnych neuronów. Sygnał jest reprezentowany przez liczbę rzeczywistą, a obliczany jest za pomocą nieliniowej funkcji zwanej funkcją aktywacji (ang. activation function). Z reguły neurony są zagregowane w warstwy (ang. layers), a każda z warstw ma przypisaną funkcję aktywacji. W najprostszych modelach sekwencyjnych sygnały są przekazywane od warstwy wejściowej (ang. input layer), kolejno przez wszystkie warstwy, aż do warstwy wyjściowej (ang. output layer). Warstwę nazywamy gęsto połączoną, jeśli każdy jej neuron jest połączony z każdym z warstwy kolejnej. Ponadto, z każdym neuronem związany jest bias (ang. bias), wpływający na wartość, która musi być przekroczona, aby neuron przekazywał sygnał. Połączenia między neuronami reprezentowane są przez zmienne zwane wagami (ang. weights). Modyfikowanie wag i biasów w trakcie prowadzenia obliczeń pozwala na dostrajanie modelu, czyli uczenie się sztucznej sieci neuronowej. Do tego celu potrzebne są dane treningowe, wraz z przypisanymi im etykietami docelowymi. Podczas nauki, sieć wykorzystuje funkcje straty (ang. loss function) do porównywania wartości etykiet docelowych z tymi przewidywanymi przez model. Na podstawie wyniku tej funkcji sieć jest w stanie określić, jak odległa była jej odpowiedź od odpowiedzi poprawnej. Ta wiedza wykorzystywana jest przez optymalizator (ang. optimizer) w celu dostrajania sieci.

Konwolucyjna sieć neuronowa (ang. convolutional neural network, CNN, ConvNet) - to szczególna klasa sieci neuronowych, szeroko wykorzystywana w analizie obrazów i wideo z uwagi na przewagę nad klasycznymi sieciami neuronowymi w przynajmniej dwóch aspektach. Podstawową różnicą między siecią gęsto połączoną a siecią konwolucyjną jest to, że ta pierwsza uczy się rozpoznawania cech globalnych, a ta druga- lokalnych wzorców. W przypadku obrazów cechy są znajdowane w małych, dwuwymiarowych oknach danych wejściowych (czyli małych wycinkach obrazu w przypadku analizy podejmowanej przez pierwszą warstwę sieci). Dzięki temu, wzorce obrazu rozpoznawane przez model są niezależne od pozycji tego wzorca na obrazie. Dla przykładu, sieć konwolucyjna po rozpoznaniu określonego wzoru w prawym dolnym rogu obrazu może rozpoznać go również np. w lewym górnym rogu obrazu. Sieć gęsta musiałaby nauczyć się tej cechy na nowo. Oznacza to, że modele konwolucyjne nie wiążą kształtu z jego położeniem w kadrze. Z tego powodu charakteryzują się one większą wydajnością i wymagają mniejszej ilości danych treningowych. Drugą zaletą sieci konwolucyjnych jest to, że uczą się hierarchii wzorców. Oznacza to, że pierwsze warstwy uczą się małych lokalnych wzorców, takich jak na przykład krawędzie czy tekstury, a kolejne bardziej skomplikowanych struktur, składających się z elementów rozpoznanych przez warstwy poprzednie. Takie podejście pozwala na wydajne uczenie się złożonych i abstrakcyjnych wzorców graficznych.


\section{Przegląd literatury związanej z uczeniem głębokim}

Poniżej znajduje się krótki przegląd literatury związanej z implementacją sieci neuronowych.

W 1989 roku w \cite{BackpropagationLeCun} zaimplementowano algorytm propagacji wstecznej w modelu głębokim, w celu rozpoznawania ręcznie pisanych cyfr w wiadomościach pocztowych. Baza danych składała się z 9298 cyfr różnej wielkości, napisanych przez wielu ludzi o różnych stylach pisania. Algorytm propagacji wstecznej pozwolił trenować sieć zaskakująco szybko, biorąc pod uwagę wielkość zbioru danych. Model znalazł zastosowanie w komercyjnych maszynach automatyzujących proces odczytywania ręcznie pisanych cyfr.

W 1992 roku w \cite{Cresceptron} zaimplementowano model o nazwie Cresceptron, który wykorzystywał uczenie nienadzorowane (nie wymagał wcześniejszego etykietowania danych przez programistów) do rozpoznawania obiektów w kadrach, w których było ich bardzo wiele. Cresceptron uczył się dowolnej liczby cech dla każdej warstwy, a każda cecha była reprezentowana przez jądro konwolucji. Był to pierwszy model wykorzystujący warstwy max pooling do redukcji rozdzielczości tensorów przyjmowanych przez daną warstwę - analizowały one okna konwolucji o rozmiarze 2x2 z krokiem równym 2 (patrz rozdział \ref{chapter4}). 

W problemach rozpoznawania mowy często używana jest rekurencyjna sieć neuronowa opublikowana w 1997 przez \cite{LSTMSchmidhuber}, wykorzystująca metodę zwaną long short-term memory (LSTM). Ta sieć jest zdolna do rozwiązywania problemów, które wymagają pamięci o wydarzeniach, które miały miejsce wiele kroków wcześniej, co jest istotne m.in. w kontekście rozpoznawania mowy. Sześć lat później LSTM zaczęło konkurować w rozwiązywaniu pewnych problemów z tradycyjnymi sieciami rozpoznającymi mowę \cite{LSTMGraves}. Później sieci LSTM zostały połączone z CTC (connectionist temporal classification) \cite{CTC}, co zostało wykorzystane przez firmę Google w 2015 roku do podniesienia wydajności sieci rozpoznających mowę w oparciu o dane zebrane dzięki Google Voice Search \cite{GVS}.

Rok 2009 przyniósł przełom w dziedzinie sprzętu wykorzystywanego do trenowania sztucznych sieci neuronowych. Firma Nvidia wytrenowała model na procesorze graficznym, udowadniając, że GPU może zwiększyć szybkość trenowania sieci około 100-krotnie, w szczególności świetnie radząc sobie z obliczeniami przeprowadzanymi na tensorach \cite{GPUOh}. 
