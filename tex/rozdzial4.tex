\chapter{Teoria i projekt}
\thispagestyle{chapterBeginStyle}
\label{chapter4}


W tym rozdziale zostały zaprezentowano informacje dotyczące bazy danych, konwolucyjnych sieci neuronowych, augmentacji danych, wykorzystania modeli uprzednio trenowanych (transfer learning), jak i implementowanej aplikacji mającej na celu usprawnić proces trenowania modeli.


\section{Dane}
Do wytrenowania sieci neuronowej zdolnej rozpoznawać emocje na zdjęcia tłumów i grup ludzi potrzebny jest odpowiedni, tj. dobrze poetykietowany zbiór danych. Znalezienie takiego zestawu okazało się nietrywialne z uwagi na brak publicznie dostępnych, poetykietowanych zbiorów zawierających zdjęcia tłumów. Ostatecznie wykorzystano zbiór Group Affect Database 3.0 \cite{GAD}. Nie jest on dostępny w internecie, ponieważ autorzy zapewniają do niego dostęp jedynie uczestnikom corocznie organizowanego przez nich konkursu Emotion Recognition in the Wild Challenge \cite{EmotiwPage}\cite{EmotiwSummary}, jednak został wyjątkowo udostępniony wyłącznie do celów akademickich na potrzeby niniejszej pracy i nie może być przekazywany dalej bez zgody autorów. 

Zbiór Group Affect Database 3.0 to ponad 2 gigabajtowa baza danych, na którą składają się 17 172 zdjęcia przypisane do jednej z trzech kategorii: emocje pozytywne (np. szczęście, miłe zaskoczenie), neutralne (np. brak emocji czy znudzenie) oraz negatywne (złość, strach, smutek, obrzydzenie czy niemiłe zaskoczenie). Ponadto, zbiór jest podzielony na 3 podzbiory: treningowy, walidacyjny i testowy (odpowiednio 57.2\%, 25,3\% i 17.5\% wszystkich zdjęć), co w domyśle ma ułatwić proces uczenia modelu. Tutaj warto zauważyć, że zbiory emocji nie są równe pod względem liczby zdjęć. Poszczególne klasy emocji zachowują podobne proporcje w podzbiorze treningowym i walidacyjnym, ale zbiór testowy nie zawiera etykiet, co uniemożliwia sztuczne dostosowywanie modelu pod niego. W treningowym zbiorze danych zdjęcia pozytywne stanowią około 40.5\% zdjęć, zdjęcia neutralne- 31.4\%, a zdjęcia negatywne tylko 28.1\%. W przypadku zbioru walidacyjnego jest to odpowiednio 40.2\%, 31.5\% i 28.3\%.

W poprzednim rozdziale (\ref{chapter3}) przytoczono, że autorzy bazy osiągnęli dokładność na walidacyjnym zbiorze danych rzędu 67.64\% i 67.15\% w przypadku swoich dwóch najlepszych modeli. Zauważono też, że niezależni deweloperzy również osiągają wysokie, przekraczające 65\% wyniki. Jest to istotne z punktu widzenia tej pracy, ponieważ daje lepszą wizję tego, jaka dokładność modelu może zostać uznana za dobrą. Trzeba jednak zauważyć również, że z uwagi na próby utrzymania modelu w jak najmniejszym rozmiarze, osiągnięcie podobnych wyników może okazać się trudne lub wręcz niemożliwe.


\section{Model konwolucyjnej sieci neuronowej}
Model rozpoznający emocje zostanie oparty na głębokiej konwolucyjnej sieci neuronowej, z uwagi na to, że są one najefektywniejsze w przypadku problemów rozpoznawania obrazów. Model będzie przyjmował trójwymiarowe tensory (mapy cech), których dwie pierwsze osie będą definiować wysokość i szerokość, natomiast trzecia oś będzie osią głębi (kanałów) obrazu. Z racji tego, że rozpatrywane będą kolorowe obrazy RGB, trzecia oś będzie mieć dokładnie trzy wymiary (dla kolorów czerwonego, zielonego i niebieskiego).

\subsection{Wartwy konwolucyjne}
Kolejne tensory tworzone przez następujące po sobie warstwy sieci również będą tensorami trójwymiarowi, ale rozmiar poszczególnych wymiarów będzie się zmieniał. I tak, szerokość i wysokość będzie maleć lub zachowywać ten sam rozmiar, natomiast wymiar głębi może przyjąć dowolną wartość, z uwagi na to, że po przejściu przez pierwszą warstwę przestaje on reprezentować nasycenie poszczególnych kolorów składowych, a zaczyna przechowywać filtry. Filtry stanowią reprezentacje określonych cech danych. Liczba filtrów jest parametrem warstwy, co oznacza, że to warstwa decyduje, jak wiele będzie ich tworzyć. W pierwszych warstwach filtry mogą kodować krawędzie czy tekstury, w kolejnych proste kształty, i tak dalej, przez coraz bardziej skomplikowane struktury, by w ostatnich warstwach reprezentować najbardziej złożone obiekty, jak ludzkie sylwetki czy twarze.

Warstwa będzie przyjmować mapę cech i dokonywać ekstrakcji łat z tych cech wejściowych. Łaty to niewielkie, dwuwymiarowe ,,okienka'' danych, z reguły o rozmiarze 3x3 lub 5x5. Można powiedzieć, że za pomocą tych okienek warstwa obserwuje tensor wejściowy. Tensorem wejściowym dla pierwszej warstwy jest obraz, a więc obserwuje ona jego kolejne fragmenty o wymiarze 3x3 lub 5x5 pikseli i przeprowadza operacje celem utworzenia wyjściowego tensora, który posłuży za mapę cech do kolejnej warstwy. Warto nadmienić, że rozmiar okna, zupełnie jak liczba filtrów, również jest parametrem warstwy i może różnić się, w zależności od jej głębokości. Z reguły jednak zachowuje stałą wartość dla całej sieci.

Konwolucja to przesuwanie okien po trójwymiarowej mapie cech. Warstwa umieszcza okno w każdym możliwym miejscu otrzymanego tensora, każdorazowo dokonując ekstrakcji łaty o rozmiarze (wysokość\_okna, szerokość\_okna, głębia\_wejściowa). Następnie każda łata jest przekształcana przez jądro konwolucji w celu uzyskania jednowymiarowego wektora o długości równej wyjściowemu rozmiarowi głębi. Warstwa łączy wszystkie te wektory w jeden trójwymiarowy tensor o rozmiarze (wysokość\_wyjściowa, szerokość\_wyjściowa, wyjściowy\_rozmiar\_głębi). Należy zaznaczyć, że wektory są układane w sposób odpowiadający ich położeniu w tensorze wejściowym. Na koniec, nowo stworzony tensor jest przekazywany do następnej warstwy.

Wysokość i szerokość tensora wejściowego może się różnić (i z reguły się różni) o tych samych parametrów tensora wyjściowego. Wynika to z faktu, że warstwa nie jest w stanie dopasować tylu okienek ile wynosi iloczyn szerokości i wysokości tensora wejściowego. Dla przykładu, jeśli okienko jest rozmiarów 3x3, to wyjściowa szerokość będzie równa szerokości wejściowej pomniejszonej o 2 (analogicznie dla wysokości). Można temu zaradzić, stosując technikę dopełnienia. Polega ona na dodawaniu wierszy i kolumn do wejściowej mapy cech w taki sposób, żeby można było zmieścić odpowiednią liczbę okien konwolucji. Na przykład, dla okna rozmiaru 3x3 wystarczy dodać po jednym wierszu u góry i dołu oraz po jednej kolumnie po lewej i prawej stronie. W praktyce jednak nie stosuje się tej techniki często, zamiast tego pozwalając tensorowi zmniejszać swoją szerokość i wysokość z warstwy na warstwę.

Warstwa nie musi ustawiać okien konwolucji w każdym możliwym miejscu. Biorąc pod uwagę fakt, że różne okna stojące obok siebie analizują częściowo te same dane, czasami opłacalne może okazać się ,,skakanie'' np. co dwie albo co trzy możliwe pozycje. Tę technikę nazywa się konwolucją kroczącą. Należy zwrócić uwagę na to, że przeskakiwanie co $n$-tej pozycji zmniejszy liczbę wygenerowanych okienek $n^2$ razy (ponieważ analizowane będzie $n$ razy mniej wierszy i $n$ razy mniej kolumn). W związku z tym, tensor wyjściowy również będzie analogicznie mniejszy. Ponownie jednak, w praktyce raczej nie stosuje się tej techniki często, zamiast tego analizując wszystkie możliwe okna konwolucji.

\subsection{Warstwy pooling}
Sieci konwolucyjne nie składają się tylko i wyłącznie z warstw konwolucyjnych. Pomiędzy tymi warstwami umieszcza się również warstwy pooling, których zadaniem jest z reguły drastyczne zmniejszenie przekazywanego tensora, z jednoczesnym zachowaniem najważniejszych cech danych. Warstwy pooling również korzystają z koncepcji okien i kroczenia, ale w tym przypadku wydaje się to być prostsze. W przypadku tych warstw, pojedynczej łaty danych nie przekształca się za pomocą jądra konwolucji, a z reguły wykonuje się na niej prostą operację tensorową, taką jak np. branie maksimum lub wartości średniej. Podczas, gdy warstwy konwolucyjne z reguły używają okien 3x3 z krokiem równym jeden, warstwy pooling używają raczej okien 2x2 z krokiem równym 2. Dzięki temu, każda wartość analizowana jest dokładnie raz, a wyjściowy tensor jest drastycznie zmniejszany. Ponadto, zastosowanie funkcji zwracającej maksimum sprawia, że z analizowanej łaty najprawdopodobniej zostanie wyciągnięta najbardziej istotna wartość. Dzieje się tak, gdyż cechy z reguły reprezentują obecność jakiegoś wzorca lub koncepcji, a najłatwiej jest je zauważyć wyciągając właśnie elementy maksymalne. Z tego też powodu funkcja zwracająca maksimum jest częściej wykorzystywana, niż funkcja zwracająca wartość średnią.

Zmniejszanie rozdzielczości kolejnych map cech przekazywanych między warstwami ma kilka zasadniczych zalet. Po pierwsze, ograniczana jest liczba współczynników, jakie muszą być wytrenowane przez model. Dzięki temu skracany jest czas trenowania sieci, ale co ważniejsze z punktu widzenia tego projektu, zmniejszany jest jej rozmiar. Ponadto, ograniczanie z góry liczby parametrów modelu pozwala na uniknięcie nadmiernego dopasowania do danych treningowych. Oprócz tego, architektura o ,,zwężających się'', ale coraz głębszych warstwach ułatwia sieci zaimplementowanie hierarchii filtrów przestrzennych, ponieważ każda następna warstwa analizuje coraz większe okna obrazu wejściowego.


\section{Augmentacja danych}
Baza danych, która posłuży do trenowania modelu, zawiera 9 815 zdjęć w treningowym zbiorze danych.
Biorąc pod uwagę jak skomplikowane zagadnienie jest analizowane, ta liczba zdjęć może okazać się niewystarczająca, aby uchronić sieć przed nadmiernym dopasowaniem do danych treningowych. 
W każdym kolejnym cyklu trenowania model będzie otrzymywał te same dane wejściowe.
Z tego powodu sieć może nie stworzyć pożądanych uogólnień (odpowiedniej hierarchii filtrów przestrzennych), które sprawdzą się podczas przetwarzania nowych danych, a zamiast tego po prostu uczyć się rozpoznawać konkretne zdjęcia ze zbioru treningowego.
Aby temu zapobiec zostanie zastosowana, często wykorzystywana w kontekście przetwarzania obrazów, technika augmentacji danych.

Augmentacja danych pozwala na rozszerzenie zbioru treningowego o nowe elementy (wygenerowane poprzez losowe przekształcenia już istniejących obrazów), które wyglądają wiarygodnie i można je przypisać do tej samej kategorii, co obraz wejściowy. Dzięki temu, w kolejnych epokach trenowania model nie będzie musiał korzystać z tych samych danych, lecz za każdym razem zostanie dla niego wygenerowany nowy zbiór. Będzie on podobny do zbioru treningowego, ale losowe przekształcenia zagwarantują, że każde zdjęcie przekazane do modelu będzie unikatowe. Zlikwiduje to możliwość dopasowywania się modelu do zbioru treningowego i niejako zostanie on ,,zmuszony'' do wykształcenia cech (stworzenia lepszych uogólnień), które rzeczywiście przydadzą się do analizy nowych zdjęć.

Przykładowe modyfikacje zdjęć, które mogą zostać zastosowane, to rozjaśnianie lub przyciemnianie, przesuwanie lub odbijanie obrazów w osi poziomej lub pionowej, przybliżanie pewnych fragmentów czy obrót o pewien losowy, niewielki kąt.

Innym wykorzystywanym razem z augmentacją danych sposobem na zmniejszenie nadmiernego dopasowywania się sieci do danych treningowych jest użycie warstwy porzucenia (ang. dropout). W tym przypadku kluczową ideą jest losowe porzucanie neuronów z modelu (razem z ich połączeniami) podczas trenowania. Zapobiega to zbytniej wspólnej adaptacji neuronów, a w konsekwencji istotnie zmniejsza nadmierne dopasowanie i zapewnia znaczną poprawę w stosunku do innych metod regularyzacji. Tę warstwę wykorzystuje się często nie tylko przy rozpoznawaniu obrazów, ale też np. przy rozpoznawaniu mowy.


\section{Rozszerzenie uprzednio trenowanej sieci neuronowej}
Problem nadmiernego dopasowania dla niewielkich zbiorów danych można skutecznie rozwiązać również korzystając z uprzednio wytrenowanej konwolucyjnej sieci neuronowej. To podejście polega na wykorzystaniu sieci, która została już wcześniej wytrenowana na innym, bardzo dużym zbiorze obrazów. Ten zbiór nie musi być jednak podobny do zbioru, którym dysponujemy. Istotne jest, aby był na tyle duży i ogólny, by można było użyć jego przestrzennej hierarchii cech w charakterze ogólnego modelu przetwarzania obrazu. Taka sieć jest już nauczona pewnych mniej lub bardziej skomplikowanych kształtów. Ta wiedza może przydać się również do rozwiązywania problemów, do których sieć nie była wcześniej szkolona. W analizowanym problemie powinna być więc szczególnie przydatna.

Oczywiście, nie można skorzystać z takiej sieci bez wprowadzania modyfikacji. Modele o najlepszych przestrzennych hierarchiach cech są uprzednio trenowane do rozpoznawania tysięcy różnych klas, a w analizowanym problemie nasz model powinien zwracać jedną z trzech kategorii opisujących emocje. Dlatego też, z wcześniej wytrenowanego modelu zostanie wyciągnięta tylko baza konwolucyjna, a następnie zostanie do niej podpięty nowy, gęsto połączony klasyfikator, który po przemapowaniu otrzymanych od niej danych będzie w stanie rozpoznawać pożądane emocje. Baza konwolucyjna to fragment sieci CNN składający się z warstw konwolucyjnych i warstw pooling, bez warstw gęstych.

By nie zniszczyć przestrzennej hierarchii cech w bazie konwolucyjnej można ją ,,zamrozić'', tj. nie pozwolić modelowi na trenowanie jej, a skupić się za to na gęsto połączonym klasyfikatorze. To tylko jedno z możliwych podejść, ale ma wielką zaletę: możliwość cachowania.

Skoro w każdym cyklu trenowania sieć będzie karmiona tymi samymi danymi (w tym przypadku augmentacja danych nie zostanie użyta), a jednocześnie baza konwolucyjna będzie zamrożona (jej wagi i biasy nie będą modyfikowane), oznacza to, że uprzednio trenowana baza konwolucyjna będzie za każdym razem przekazywać identyczne tensory do gęsto połączonego klasyfikatora. Nie ma więc powodu, by każdorazowo odczytywać z dysku tysiące zdjęć, a następnie w każdej iteracji trenowania karmić nimi tą samą sieć, oczekując tych samych wyników. Zamiast tego, zostanie zaimplementowany cache, który dla danej bazy konwolucyjnej i dla danego sposobu preprocessingu danych, przetworzy zdjęcia tylko raz, a następnie zapisze zwrócone tensory w pamięci po to, by gęsto połączony klasyfikator mógł z nich korzystać bez każdorazowego przetwarzania ich przez bazę konwolucyjną. Oczywiście, ten mechanizm musi być w stanie rozpoznawać, czy przy kolejnym uruchomieniu aplikacji dane zostały przetworzone w taki sam sposób i czy została użyta ta sama baza konwolucyjna. Jeśli coś się zmieniło, nowe wartości muszą zostać przetworzone od nowa i również zapisane na dysku.

Dzięki wykorzystaniu tego podejścia zostanie wyeliminowany najbardziej kosztowny obliczeniowo element przetwarzania danych, co ma olbrzymie znaczenia praktyczne. Po pierwsze, pozwoli to na przeprowadzanie nawet setek cykli uczenia bez konieczności oczekiwania wielu godzin na wyniki. Po drugie, pozwoli na ,,hurtowe'' trenowanie modeli dla różnych metaparametrów, co ułatwi podejmowanie decyzji, który z nich jest warty dalszego rozwijania.


\section{Projekt aplikacji}
Wyżej opisana funkcjonalność będzie elementem aplikacji, która zostanie zaimplementowana w celu możliwie maksymalnego zautomatyzowania procesu trenowania sieci neuronowych. Sercem aplikacji, a zaraz sposobem na łatwe nią sterowanie, będzie plik konfiguracyjny przechowujący ścieżki do wszystkich katalogów wykorzystywanych przez aplikacje. Oprócz tego będzie przechowywał metaparametry wykorzystywane przy wstępnej obróbce danych, augmentacji danych i trenowaniu modeli, a ponadto również informacje o sposobie formatowania wykresów prezentujący wyniki oraz o tym, jakie logi mają być wyświetlane w konsoli dla użytkownika.

Korzystając z tych danych, aplikacja zbuduje swój model sieci neuronowej, lub skorzysta ze zdefiniowanej bazy konwolucyjnej. W obu przypadkach odpowiednio przygotuje dane do procesu trenowania. W pierwszym przypadku wykorzysta dane z odpowiedniej ścieżki, uprzednio te dane augmentując lub nie, w zależności od konfiguracji. W drugim przypadku wykorzysta ścieżkę do zcachowanych danych, a jeśli tej ścieżki nie odnajdzie, lub nie odnajdzie cacha zapisanego dla tej konkretnej bazy konwolucyjnej i sposobu preprocessingu danych, skorzysta ze ścieżki do bazy celem stworzenia odpowiedniego cacha. Oprócz tego aplikacja, korzystając ze zdefiniowanych ścieżek, zapisze na dysku każdy wytrenowany model, jak i dane potrzebne do zbudowania wykresów podsumowujących jego wydajność. Ponadto, każdorazowo zbuduje i wyświetli wspomniane wykresy przedstawiające osiągniętą dokładność oraz stratę, zarówno dla zbioru walidacyjnego, jak i treningowego. Z uwagi na to, że niektóre czynności są dość czasochłonne (np. tworzenie cacha dla całego zbioru danych), wszystkie kluczowe akcje podejmowane przez aplikacje będą logowane, by użytkownik mógł wiedzieć, nad czym w danym momencie aplikacja pracuje. Oprócz tego, w konsoli wypisywana będzie też architektura modelu i ostrzeżenia związane z przepełnianiem się pamięci karty graficznej. Wszystkie z tych informacji użytkownik będzie mógł włączyć lub wyłączyć za pomocą pliku konfiguracyjnego.

Ponadto, zostanie utworzony skrypt pozwalający na wygodne testowanie zapisanych wcześniej modeli dla dowolnych zdjęć. Skrypt będzie korzystał z innego pliku konfiguracyjnego, który pozwoli użytkownikowi na zdefiniowanie ścieżki do modelu do wczytania, wypisanie wyników na konsoli lub zdefiniowanie pliku do ich zapisu w wygodnym formacie, ale też umożliwi określenie poziomu szczegółowości wypisywanych rezultatów (zwięźle- tylko przewidywana emocja, bądź obszernie- dokładne przewidywanie prawdopodobieństwo dla każdej emocji) oraz zdefiniowanie informacji, które mają być logowane w konsoli. Ponadto, użytkownik podczas uruchomienia skryptu będzie mógł za pomocą parametrów uruchomienia przekazać mu ścieżki do plików lub katalogów zawierających zdjęcia. Skrypt załaduje wskazany w pliku konfiguracyjnym model, następnie przetworzy te z otrzymanych plików ze zdjęciami, które są w odpowiednim formacie, a ostatecznie zwróci pożądane przewidywania w zdefiniowanej przez użytkownika formie. 
